---
id: lesson-6y7pw
---

You may already have an LLM that you prefer, and API keys from testing it out.

If you don't already have an LLM, I recommend checking out my previous post on it. It explains the various metrics you need to understand in order to choose an LLM effectively.

I also recommend checking the Vercel AI SDK's supported providers. We'll be using the AI SDK, so sticking to their supported providers will give you a better experience.

And if you don't want the stress of choosing an LLM, let me make a recommendation. Any of Google's recent models are extremely cheap, have relatively generous rate limits and extremely large context windows. Getting a Google API key is also pretty simple.

This exercise is complete when:

- You have an API key for your preferred LLM in your .env file.
- You have downloaded the correct AI SDK package to your repo.
