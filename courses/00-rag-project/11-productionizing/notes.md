- TRY adding rate limits
- TRY adding guard rails & security layers
- TRY writing evals for your guard rails
- TRY: adding OTEL for observability
- TRY: hooking up OTEL to Datadog

---

How do you allow users to use their own API keys in a secure way? For instance, putting in their OpenAI API key?

---

Need to think about error handling during streaming. How to fail gracefully.

---

Need to think about caching LLM responses, and making that caching feel natural.
